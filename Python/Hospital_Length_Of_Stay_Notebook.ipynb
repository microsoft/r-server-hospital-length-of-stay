{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hospital Length of Stay\n",
    "\n",
    "In order for hospitals to optimize resource allocation, it is important to predict accurately how long a newly admitted patient will stay in the hospital.\n",
    "\n",
    "This notebook takes advantage of the power of SQL Server and RevoScalePy. The tables are all stored in a SQL Server, and most of the computations are done by loading chunks of data in-memory instead of the whole dataset.\n",
    "\n",
    "It does the following: \n",
    "\n",
    " * **Step 0: Packages and Compute Contexts**\n",
    " * **Step 1: Processing and Cleaning**\n",
    " * **Step 2: Feature Engineering**\n",
    " * **Step 3: Training and Evalutating a Random Forest, Boosted Trees, Fast Trees, and a Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Packages and Compute Contexts\n",
    "\n",
    "#### In this step, we set up the connection string to access a SQL Server Database and load the necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WARNING.\n",
    "# We recommend not using Internet Explorer as it does not support plotting, and may crash your session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages.\n",
    "import os, sys\n",
    "from numpy import mean\n",
    "from math import sqrt\n",
    "from pandas import Series, DataFrame, to_numeric\n",
    "import pyodbc\n",
    "\n",
    "from revoscalepy import RxInSqlServer, RxLocalSeq, rx_set_compute_context, rx_import, rx_data_step, rx_summary\n",
    "from revoscalepy import rx_get_var_names, RxSqlServerData, RxTextData, rx_serialize_model, rx_import, rx_data_step\n",
    "from revoscalepy import rx_set_compute_context, rx_import, rx_data_step, rx_summary\n",
    "from revoscalepy import rx_dforest, rx_btrees, rx_predict, RxOdbcData, rx_get_var_info, RxSqlServerData, rx_get_var_names\n",
    "from revoscalepy import RxInSqlServer, RxLocalSeq, rx_set_compute_context, rx_write_object\n",
    "\n",
    "from microsoftml import rx_fast_trees, rx_neural_network, adadelta_optimizer\n",
    "from microsoftml import rx_predict as ml_predict\n",
    "\n",
    "from length_of_stay_utils import train_test_split, create_formula, write_rts_model, evaluate_model, get_num_rows, drop_view, alter_column\n",
    "\n",
    "# Autoreload when modules are changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Compute Contexts: user to input Server Name, database name, UID and Password. \n",
    "from SQLConnection import *\n",
    "\n",
    "# Choose a database name and create it. \n",
    "db = \"Hospital\"\n",
    "\n",
    "## Connect to the master database only to create a new database. Change UID and PWD if you modified them. \n",
    "master_connection_string = \"Driver=SQL Server;Server=localhost;Database=master;UID=XXYOURSQLUSER;PWD=XXYOURSQLPW\"\n",
    "\n",
    "## Create database. \n",
    "pyodbc_cnxn = pyodbc.connect(master_connection_string)\n",
    "pyodbc_cursor = pyodbc_cnxn.cursor()\n",
    "pyodbc_cursor.execute(\"if not exists(SELECT * FROM sys.databases WHERE name = '{}') CREATE DATABASE {};\".format(db, db))\n",
    "pyodbc_cursor.close()\n",
    "pyodbc_cnxn.commit()\n",
    "pyodbc_cnxn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Pre-Processing and Cleaning\n",
    "\n",
    "In this step, we: \n",
    "\n",
    "**1.** Upload the data set to SQL.\n",
    "\n",
    "**2.** Clean the merged data set: we replace NAs with the mode (categorical variables) or mean (continuous variables).\n",
    "\n",
    "**Input:**  Data Set LengthOfStay.csv\n",
    "\n",
    "**Output:** Cleaned raw data set LoS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the compute context to Local. \n",
    "rx_set_compute_context(local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Upload the data set to SQL.\n",
    "## Point to the input data set while specifying the classes.\n",
    "file_path = \"..\\\\Data\"\n",
    "LoS_text = RxTextData(file = os.path.join(file_path, \"LengthOfStay.csv\"), column_info=col_type_info)\n",
    "\n",
    "## Upload the table to SQL. \n",
    "LengthOfStay_sql = RxSqlServerData(table = \"LengthOfStay\", connection_string = connection_string)\n",
    "rx_data_step(input_data = LoS_text, output_file = LengthOfStay_sql, overwrite = True)\n",
    "\n",
    "print(\"Data exported to SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine if LengthOfStay has missing values\n",
    "\n",
    "table = \"LengthOfStay\"\n",
    "\n",
    "# First, get the names and types of the variables to be treated.\n",
    "data_sql = RxSqlServerData(table = table, connection_string = connection_string, stringsAsFactors = True)\n",
    "colnames = rx_get_var_names(data_sql)\n",
    "\n",
    "# Then, get the names of the variables that actually have missing values. Assumption: no NA in eid, lengthofstay, or dates. \n",
    "var = [x for x in colnames if x not in [\"eid\", \"lengthofstay\", \"vdate\", \"discharged\"]]\n",
    "f = \"+\".join(var)\n",
    "summary = rx_summary(formula = f, data = data_sql, by_term = True).summary_data_frame\n",
    "\n",
    "var_with_NA = summary[summary[\"MissingObs\"] > 0]\n",
    "\n",
    "method = None\n",
    "if var_with_NA.empty:\n",
    "    print(\"No missing values.\")\n",
    "    print(\"You can move to step 2.\")\n",
    "    missing = False\n",
    "else:\n",
    "    print(\"Variables containing missing values are:\")\n",
    "    print(var_with_NA)\n",
    "    print(\"Apply one of the methods below to fill missing values.\")\n",
    "    missing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If applicable, NULL is replaced with the mode (categorical variables: integer or character) or mean (continuous variables).\n",
    "\n",
    "if(missing == False):\n",
    "    print(\"Nothing to clean\")\n",
    "    LengthOfStay_cleaned_sql = RxSqlServerData(table = table, connection_string = connection_string)\n",
    "else:\n",
    "    print(\"Fill with mode and mean\")\n",
    "\n",
    "    # Get the variables types (categortical vs. continuous)\n",
    "    categ_names = []\n",
    "    contin_names = []\n",
    "    for index, row in var_with_NA.iterrows():\n",
    "        nameSeries = var_with_NA[\"Name\"]\n",
    "        name = nameSeries.to_string().split()[-1]\n",
    "        if col_info[name][\"type\"] == \"numeric\":\n",
    "            contin_names.append(name)\n",
    "        else:\n",
    "            categ_names.append(name)\n",
    "\n",
    "    # Function to replace missing values with the mode (categorical variables) or mean (continuous variables)\n",
    "    def fill_NA_mode_mean(dataset, context):\n",
    "        data = DataFrame(dataset)\n",
    "        for name in categ_names:\n",
    "            data.loc[data[name].isnull(),name] = data[name].mode().iloc[0]\n",
    "        for name in contin_names:\n",
    "            data.loc[data[name].isnull(), name] = data[name].mean()\n",
    "        return data\n",
    "\n",
    "    # Apply this function to LengthOfStay by wrapping it up in rxDataStep. Output is written to LoS0.\n",
    "    # We drop the LoS0 view in case the SQL Stored Procedure was executed in the same database before.\n",
    "    pyodbc_cnxn = pyodbc.connect(connection_string)\n",
    "    drop_view(\"LoS0\", connection_string)\n",
    "\n",
    "    LoS0_sql = RxSqlServerData(table = \"LoS0\", connection_string = connection_string)\n",
    "    rx_data_step(input_data = LengthOfStay_sql, output_file = LoS0_sql, overwrite = True, transform_function = fill_NA_mode_mean)\n",
    "   \n",
    "    LengthOfStay_cleaned_sql = RxSqlServerData(table = \"LoS0\", connectionString = connection_string)    \n",
    "    \n",
    "print(\"Data cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering\n",
    "\n",
    "In this step, we:\n",
    "\n",
    "**1.** Standardize the continuous variables (Z-score).\n",
    "\n",
    "**2.** Create the variable number_of_issues: the number of preidentified medical conditions.\n",
    "\n",
    "**Input:** Data set before feature engineering LengthOfStay.\n",
    "\n",
    "**Output:** Data set with new features LoS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the mean and standard deviation of continuous variables.\n",
    "col_list = rx_get_var_names(LengthOfStay_cleaned_sql)\n",
    "f = \"+\".join(col_list)\n",
    "summary = rx_summary(formula = f, data = LengthOfStay_cleaned_sql, by_term = True).summary_data_frame\n",
    "\n",
    "names = [\"hematocrit\", \"neutrophils\", \"sodium\", \"glucose\", \"bloodureanitro\", \"creatinine\", \"bmi\", \"pulse\", \"respiration\"]\n",
    "statistics = summary[summary[\"Name\"].isin(names)]\n",
    "statistics = statistics[[\"Name\", \"Mean\", \"StdDev\"]]\n",
    "\n",
    "# standardization transform function\n",
    "def standardize(data, context):\n",
    "    for n, row in statistics.iterrows():\n",
    "        data[[row[\"Name\"]]] = (data[[row[\"Name\"]]] - row[\"Mean\"])/row[\"StdDev\"]\n",
    "    return data\n",
    "\n",
    "# number_of_issues transform function\n",
    "def calculate_number_of_issues(data, context):\n",
    "    data[\"number_of_issues\"] = to_numeric(data[\"hemo\"]) + to_numeric(data[\"dialysisrenalendstage\"]) + to_numeric(data[\"asthma\"])\\\n",
    "                               + to_numeric(data[\"irondef\"]) + to_numeric(data[\"pneum\"]) + to_numeric(data[\"substancedependence\"])\\\n",
    "                               + to_numeric(data[\"psychologicaldisordermajor\"]) + to_numeric(data[\"depress\"])\\\n",
    "                               + to_numeric(data[\"psychother\"]) + to_numeric(data[\"fibrosisandother\"]) + to_numeric(data[\"malnutrition\"])\n",
    "    return data\n",
    "\n",
    "# Combine transform functions into one overarching transform\n",
    "def transform(dataset, context):\n",
    "    data = DataFrame(dataset)\n",
    "    data = standardize(data, context)\n",
    "    data = calculate_number_of_issues(data, context)\n",
    "    return data\n",
    "\n",
    "# We drop the LoS view in case the SQL Stored Procedure was executed in the same database before.\n",
    "drop_view(\"LoS\", connection_string)\n",
    "\n",
    "# Standardize the cleaned table by wrapping it up in rxDataStep. Output is written to LoS_standard.\n",
    "table_name = \"LengthOfStay\" if missing is False else \"LoS0\"\n",
    "LengthOfStay_cleaned_sql = RxSqlServerData(sql_query = \"SELECT * FROM [{}]\".format(table_name),\n",
    "                                           connection_string = connection_string)\n",
    "LoS_sql = RxSqlServerData(table = \"LoS\", connection_string = connection_string)\n",
    "rx_data_step(input_data = LengthOfStay_cleaned_sql, output_file = LoS_sql, overwrite = True, transform_function = transform)\n",
    "\n",
    "# Converting number_of_issues to character with a SQL query because as.character in rxDataStep is crashing.\n",
    "alter_column(\"LoS\", \"number_of_issues\", \"varchar(2)\", connection_string)\n",
    "alter_column(\"LoS\", \"lengthofstay\", \"float\", connection_string)\n",
    "\n",
    "print(\"Feature Engineering Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training and Evaluating the Models\n",
    "\n",
    "In this step we:\n",
    "\n",
    "**1.** Split randomly the data set LoS into a training (LoS_Train) and a testing (LoS_Test) set.\n",
    " \n",
    "**2.** Train a Random Forest, Boosted Trees, Fast Trees, and Neural Network models on LoS_Train, and save them to SQL. \n",
    "\n",
    "**3.** Score the models on LoS_Test.\n",
    "\n",
    "**Input:** Data set LoS.\n",
    "\n",
    "**Output:** Random forest, Boosted Trees, Fast Trees, and Neural Network models saved to SQL and performance metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Point to the SQL table with the data set for modeling. Strings will be converted to factors.\n",
    "LoS = RxSqlServerData(table = \"LoS\", connection_string = connection_string, strings_as_factors = True)\n",
    "\n",
    "print(col_type_and_factor_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly split the data into a training set and a testing set, with a splitting % p.\n",
    "# p % goes to the training set, and the rest goes to the testing set. Default is 70%.\n",
    "\n",
    "p = 70\n",
    "\n",
    "## Create the Train_Id table containing Lead_Id of training set.\n",
    "train_test_split(\"eid\", \"LoS\", \"Train_Id\", p, connection_string)\n",
    "\n",
    "## Point to the training set. It will be created on the fly when training models.\n",
    "variables_all = rx_get_var_names(LoS)\n",
    "variables_to_remove = [\"eid\", \"vdate\", \"discharged\", \"facid\"]\n",
    "training_variables = [x for x in variables_all if x not in variables_to_remove]\n",
    "LoS_Train = RxSqlServerData(sql_query = \"SELECT eid, {} FROM LoS WHERE eid IN (SELECT eid from Train_Id)\".format(\n",
    "    ', '.join(training_variables)), connection_string = connection_string, column_info = col_type_and_factor_info\n",
    ")\n",
    "\n",
    "## Point to the testing set. It will be created on the fly when testing models.\n",
    "LoS_Test = RxSqlServerData(sql_query = \"SELECT eid, {} FROM LoS WHERE eid NOT IN (SELECT eid from Train_Id)\".format(\n",
    "    ', '.join(training_variables)), connection_string = connection_string, column_info = col_type_and_factor_info\n",
    ")\n",
    "\n",
    "print(\"Splitting completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the formula after removing variables not used in the modeling.\n",
    "formula = create_formula(\"lengthofstay\", variables_all, variables_to_remove)\n",
    "print(\"Formula: \", formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_rows = get_num_rows(\"Train_Id\", connection_string)\n",
    "\n",
    "# Define functions to tune rx_dforest and rx_btrees\n",
    "def tune_rx_dforest(formula, data, n_tree_list, cp_list, cc):\n",
    "    print(\"Tuning rx_dforest\")\n",
    "    best_error = sys.maxsize\n",
    "    best_model = None\n",
    "    for nt in n_tree_list:\n",
    "        for cp in cp_list:\n",
    "            model = rx_dforest(formula=formula,\n",
    "                               data=data,\n",
    "                               n_tree=nt,\n",
    "                               cp=cp,\n",
    "                               min_split=int(sqrt(num_rows)),\n",
    "                               max_num_bins=int(sqrt(num_rows)),\n",
    "                               seed=5,\n",
    "                               compute_context=cc)\n",
    "            error = model.oob_err['oob.err'][model.ntree - 1]\n",
    "            print(\"OOB Error: {} \\t n_tree: {} \\t cp: {}\".format(error, nt, cp))\n",
    "            if error < best_error:\n",
    "                best_error = error\n",
    "                best_model = model\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def tune_rx_btrees(formula, data, n_tree_list, lr_list, cp_list, cc):\n",
    "    print(\"Tuning rx_btrees\")\n",
    "    best_error = sys.maxsize\n",
    "    best_model = None\n",
    "    for nt in n_tree_list:\n",
    "        for lr in lr_list:\n",
    "            for cp in cp_list:\n",
    "                model = rx_btrees(formula=formula,\n",
    "                                  data=data,\n",
    "                                  n_tree=nt,\n",
    "                                  learning_rate=lr,\n",
    "                                  cp=cp,\n",
    "                                  loss_function=\"gaussian\",\n",
    "                                  min_split=int(sqrt(num_rows)),\n",
    "                                  max_num_bins=int(sqrt(num_rows)),\n",
    "                                  seed=9,\n",
    "                                  compute_context=cc)\n",
    "                error = model.oob_err['oob.err'][model.ntree - 1]\n",
    "                print(\"OOB Error: {} \\t n_tree: {} \\t learning_rate: {} \\t cp: {}\".format(error, nt, lr, cp))\n",
    "                if error < best_error:\n",
    "                    print(\"^^^ New best model!\")\n",
    "                    best_error = error\n",
    "                    best_model = model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the Random Forest.\n",
    "forest_model = tune_rx_dforest(formula, LoS_Train, n_tree_list=[40], cp_list=[0.00005], cc=sql)\n",
    "\n",
    "print(\"Training Regression RF done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the Random Forest in SQL. The compute context is set to local in order to export the model.\n",
    "write_rts_model(forest_model, \"RF\", connection_string)\n",
    "\n",
    "print(\"RF model uploaded to SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the Boosted Trees model. This tunes on the basis of minimizing oob error.\n",
    "boosted_model = tune_rx_btrees(formula, LoS_Train, n_tree_list=[40], lr_list=[0.3], cp_list=[0.00005], cc=sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the Boosted Trees in SQL. The compute context is set to Local in order to export the model.\n",
    "rx_set_compute_context(local)\n",
    "\n",
    "write_rts_model(boosted_model, \"GBT\", connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the Fast Trees model.\n",
    "fast_model = rx_fast_trees(formula=formula,\n",
    "                          data=LoS_Train,\n",
    "                          method=\"regression\",\n",
    "                          num_trees=40,\n",
    "                          learning_rate=0.2,\n",
    "                          split_fraction=5/24,\n",
    "                          min_split=10,\n",
    "                          compute_context=sql)\n",
    "\n",
    "print(\"Training Fast Trees done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the Fast Trees in SQL. The compute context is set to Local in order to export the model.\n",
    "write_rts_model(fast_model, \"FT\", connection_string)\n",
    "\n",
    "print(\"Fast Trees model uploaded to SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the Neural Network model.\n",
    "NN_model = rx_neural_network(formula=formula,\n",
    "                            data=LoS_Train,\n",
    "                            method=\"regression\",\n",
    "                            num_hidden_nodes=128,\n",
    "                            num_iterations=100,\n",
    "                            optimizer=adadelta_optimizer(),\n",
    "                            mini_batch_size=20,\n",
    "                            compute_context=sql)\n",
    "\n",
    "print(\"Training Neural Network done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_rts_model(NN_model, \"NN\", connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Scoring \n",
    "\n",
    "# Make Predictions, then import them into Python.\n",
    "forest_prediction_sql = RxSqlServerData(table = \"Forest_Prediction\",\n",
    "                                        strings_as_factors = True,\n",
    "                                        connection_string = connection_string)\n",
    "rx_predict(forest_model,\n",
    "           data = LoS_Test,\n",
    "           output_data = forest_prediction_sql,\n",
    "           type = \"response\",\n",
    "           extra_vars_to_write = [\"lengthofstay\", \"eid\"],\n",
    "           overwrite = True)\n",
    "\n",
    "# Compute the performance metrics of the model.\n",
    "forest_prediction = rx_import(input_data = forest_prediction_sql)\n",
    "forest_metrics = evaluate_model(observed = forest_prediction['lengthofstay'],\n",
    "                                predicted = forest_prediction['lengthofstay_Pred'],\n",
    "                                model = \"RF\")\n",
    "\n",
    "print(\"Scoring Random Forest (rxDForest) done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boosted Trees Scoring\n",
    "## Make Predictions, then import them into R. \n",
    "boosted_prediction_sql = RxSqlServerData(table = \"Boosted_Prediction\",\n",
    "                                         strings_as_factors = True,\n",
    "                                         connection_string = connection_string)\n",
    "rx_predict(boosted_model,\n",
    "           data = LoS_Test,\n",
    "           output_data = boosted_prediction_sql,\n",
    "           extra_vars_to_write = [\"lengthofstay\", \"eid\"],\n",
    "           overwrite = True)\n",
    "\n",
    "# Compute the performance metrics of the model.\n",
    "boosted_prediction = rx_import(input_data = boosted_prediction_sql)\n",
    "boosted_metrics = evaluate_model(observed = boosted_prediction['lengthofstay'],\n",
    "                                 predicted = boosted_prediction['lengthofstay_Pred'],\n",
    "                                 model = \"GBT\")\n",
    "\n",
    "print(\"Scoring Boosted Trees (rx_btrees) done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make Predictions, then write them to a table.\n",
    "LoS_Test_import = rx_import(input_data=LoS_Test)\n",
    "fast_prediction = ml_predict(fast_model, data=LoS_Test_import, extra_vars_to_write=[\"lengthofstay\", \"eid\"], overwrite=True)\n",
    "fast_prediction_sql = RxSqlServerData(table=\"Fast_Prediction\", strings_as_factors=True, connection_string=connection_string)\n",
    "rx_data_step(input_data=fast_prediction, output_file=fast_prediction_sql, overwrite=True)\n",
    "\n",
    "# Compute the performance metrics of the model.\n",
    "fast_metrics = evaluate_model(observed=fast_prediction['lengthofstay'], predicted=fast_prediction['Score'], model=\"FT\")\n",
    "\n",
    "print(\"Scoring Fast Trees (rx_fast_trees) done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make Predictions, then write them to a table.\n",
    "NN_prediction = ml_predict(NN_model, data=LoS_Test_import, extra_vars_to_write=[\"lengthofstay\", \"eid\"], overwrite=True)\n",
    "NN_prediction_sql = RxSqlServerData(table=\"NN_Prediction\", strings_as_factors=True, connection_string=connection_string)\n",
    "rx_data_step(input_data=NN_prediction, output_file=NN_prediction_sql, overwrite=True)\n",
    "\n",
    "# Compute the performance metrics of the model.\n",
    "NN_metrics = evaluate_model(observed=NN_prediction['lengthofstay'], predicted=NN_prediction['Score'], model=\"NN\")\n",
    "\n",
    "print(\"Scoring Neural Networks (rx_neural_networks) done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to Master Predictions Table (LoS_Predictions)\n",
    "query = \"\"\"SELECT LengthOfStay.eid, CONVERT(DATE, LengthOfStay.vdate, 110) as vdate, LengthOfStay.rcount, LengthOfStay.gender,\n",
    "               LengthOfStay.dialysisrenalendstage, LengthOfStay.asthma, LengthOfStay.irondef, LengthOfStay.pneum, LengthOfStay.substancedependence,\n",
    "               LengthOfStay.psychologicaldisordermajor, LengthOfStay.depress, LengthOfStay.psychother, LengthOfStay.fibrosisandother,\n",
    "               LengthOfStay.malnutrition, LengthOfStay.hemo, LengthOfStay.hematocrit, LengthOfStay.neutrophils, LengthOfStay.sodium,\n",
    "               LengthOfStay.glucose, LengthOfStay.bloodureanitro, LengthOfStay.creatinine, LengthOfStay.bmi, LengthOfStay.pulse,\n",
    "               LengthOfStay.respiration, number_of_issues, LengthOfStay.secondarydiagnosisnonicd9,\n",
    "               CONVERT(DATE, LengthOfStay.discharged, 110) as discharged, LengthOfStay.facid, LoS.lengthofstay,\n",
    "               CONVERT(DATE, CONVERT(DATETIME, LengthOfStay.vdate, 110) + CAST(ROUND(Score, 0) as int), 110) as discharged_Pred,\n",
    "               CAST(ROUND(Score, 0) as int) as lengthofstay_Pred\n",
    "         FROM LoS JOIN Fast_Prediction ON LoS.eid = Fast_Prediction.eid JOIN LengthOfStay ON LoS.eid = LengthOfStay.eid;\"\"\"\n",
    "results_sql = RxSqlServerData(sql_query=query, connection_string=connection_string)\n",
    "los_pred_sql = RxSqlServerData(table=\"LoS_Predictions\", connection_string=connection_string)\n",
    "rx_data_step(results_sql, los_pred_sql, overwrite=True)\n",
    "print(\"Writing LoS_Predictions done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
